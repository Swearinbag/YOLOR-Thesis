Scanning images: 100%|████████████████████| 1478/1478 [00:00<00:00, 5219.72it/s]
Scanning labels PCB-upright-29/train/labels.cache3 (1226 found, 0 missing, 252 empty, 0 duplicate, for 1478 images): 1478it [00:00, 10304.30it/s]
Scanning images: 100%|██████████████████████| 192/192 [00:00<00:00, 2226.05it/s]
Scanning labels PCB-upright-29/valid/labels.cache3 (192 found, 0 missing, 0 empty, 0 duplicate, for 192 images): 192it [00:00, 4096.98it/s]
Images sizes do not match. This will causes images to be display incorrectly in the UI.
Image sizes 640 train, 640 test
Using 4 dataloader workers
Logging results to runs/train/yolor_p675
Starting training for 1000 epochs...
     Epoch   gpu_mem       box       obj       cls     total   targets  img_size
  0%|                                                   | 0/106 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 637, in <module>
    train(hyp, opt, device, tb_writer, wandb)
  File "train.py", line 378, in train
    scaler.scale(loss).backward()
  File "/scratch/anaconda3/envs/wvgPCB/lib/python3.7/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/scratch/anaconda3/envs/wvgPCB/lib/python3.7/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 228.00 MiB (GPU 0; 7.79 GiB total capacity; 5.84 GiB already allocated; 233.38 MiB free; 6.27 GiB reserved in total by PyTorch)